

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://debugging.oss-cn-hangzhou.aliyuncs.com/debugIcon.jpg">
  <link rel="icon" href="https://debugging.oss-cn-hangzhou.aliyuncs.com/debugIcon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="debuggingWorld">
  <meta name="keywords" content="">
  
    <meta name="description" content="1. 整体架构 　　LangChain是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。  langchain-core: 基础抽象和 LangChain 表达式语言。 langchain-community：第三方集成。  例如 langchain-openai、langchain-anthropic 等。  langchain: Chains, agents, and retriev">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain——开篇">
<meta property="og:url" content="http://example.com/2024/08/14/LangChain%E2%80%94%E2%80%94%E5%BC%80%E7%AF%87/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. 整体架构 　　LangChain是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。  langchain-core: 基础抽象和 LangChain 表达式语言。 langchain-community：第三方集成。  例如 langchain-openai、langchain-anthropic 等。  langchain: Chains, agents, and retriev">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142032208.png">
<meta property="article:published_time" content="2024-08-14T03:10:02.000Z">
<meta property="article:modified_time" content="2025-09-01T02:21:27.784Z">
<meta property="article:author" content="debuggingWorld">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142032208.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>LangChain——开篇 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/iconfont.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.0","typing":{"enable":true,"typeSpeed":90,"cursorChar":"<img src=\"https://debugging.oss-cn-hangzhou.aliyuncs.com/喜爱.png\" height=\"35\" width=\"35\" />","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>猫和少年</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://debugging.oss-cn-hangzhou.aliyuncs.com/art_bg.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="LangChain——开篇"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-14 11:10" pubdate>
          2024年8月14日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          9.4k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          30 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">LangChain——开篇</h1>
            
            <div class="markdown-body">
              
              <h3 id="整体架构">1. 整体架构</h3>
<p>　　<strong>LangChain</strong>是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。</p>
<ul>
<li><strong><code>langchain-core</code></strong>: 基础抽象和 LangChain
表达式语言。</li>
<li><strong><code>langchain-community</code></strong>：第三方集成。
<ul>
<li>例如 langchain-openai、langchain-anthropic 等。</li>
</ul></li>
<li><strong><code>langchain</code></strong>: Chains, agents, and
retrieval strategies that make up an application's cognitive
architecture.</li>
<li><strong><code>LangGraph</code></strong>: Build robust and stateful
multi-actor applications with LLMs by modeling steps as edges and nodes
in a graph.</li>
<li><strong><code>LangServe</code></strong>: Deploy LangChain chains as
REST APIs.</li>
<li><strong><code>LangSmith</code></strong>: A developer platform that
lets you debug, test, evaluate, and monitor LLM applications.</li>
</ul>
<p><img
src="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142057648.svg" srcset="/img/loading.gif" lazyload /></p>
<p><a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/introduction/">【传送门】</a></p>
<h3 id="使用llm">2. 使用LLM</h3>
<p><a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/tutorials/llm_chain/">【传送门】</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    messages = [<br>        SystemMessage(content=<span class="hljs-string">&quot;Translate the following from English into chinese&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;hi!&quot;</span>),<br>    ]<br><br>    llmResult = model.invoke(messages)<br>    parser = StrOutputParser()<br>    result = parser.invoke(llmResult)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>链式调用：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_core.messages <span class="hljs-keyword">import</span> HumanMessage, SystemMessage<br><span class="hljs-keyword">from</span> langchain_core.output_parsers <span class="hljs-keyword">import</span> StrOutputParser<br><span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> OpenAI, ChatOpenAI<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    messages = [<br>        SystemMessage(content=<span class="hljs-string">&quot;Translate the following from English into chinese&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;hi!&quot;</span>),<br>    ]<br><br>    parser = StrOutputParser()<br>    chain = model | parser<br>    result = chain.invoke(messages)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<h3 id="prompttemplates">2. PromptTemplates</h3>
<p>　　PromptTemplates are a concept in LangChain designed to assist
with this transformation. They take in raw user input and return data (a
prompt) that is ready to pass into a language model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">system_template = <span class="hljs-string">&quot;Translate the following into &#123;language&#125;:&quot;</span><br>prompt_template = ChatPromptTemplate.from_messages(<br>    [(<span class="hljs-string">&quot;system&quot;</span>, system_template), (<span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;&#123;text&#125;&quot;</span>)]<br>)<br><span class="hljs-comment"># 查看转换结果</span><br>messages = prompt_template.invoke(&#123;<span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;hi&quot;</span>&#125;)<br><span class="hljs-built_in">print</span>(messages.to_messages())<br></code></pre></td></tr></table></figure>
<p><strong>Chaining together components with LCEL(LangChain Expression
Language )</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br>    parser = StrOutputParser()<br><br>    system_template = <span class="hljs-string">&quot;Translate the following into &#123;language&#125;:&quot;</span><br>    prompt_template = ChatPromptTemplate.from_messages(<br>        [(<span class="hljs-string">&quot;system&quot;</span>, system_template), (<span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;&#123;text&#125;&quot;</span>)]<br>    )<br><br>    chain = prompt_template | model | parser<br>    result = chain.invoke(&#123;<span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;hi&quot;</span>&#125;)<br>    <span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p><strong>MessagesPlaceholder 方式：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    prompt = ChatPromptTemplate.from_messages(<br>        [(<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;You are a helpful assistant. Answer all questions to the best of your ability.&quot;</span>),<br>         MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;messages&quot;</span>)]<br>    )<br><br>    chain = prompt | model<br>    response = chain.invoke(&#123;<span class="hljs-string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="hljs-string">&quot;hi! I&#x27;m bob&quot;</span>)]&#125;)<br>    <span class="hljs-built_in">print</span>(response.content)<br></code></pre></td></tr></table></figure>
<p><strong>两种方式结合：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    prompt = ChatPromptTemplate.from_messages(<br>        [(<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;Answer all questions to the best of your ability in &#123;language&#125;.&quot;</span>),<br>         MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;messages&quot;</span>)]<br>    )<br><br>    chain = prompt | model<br>    response = chain.invoke(<br>        &#123;<span class="hljs-string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="hljs-string">&quot;debug the world&quot;</span>)], <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span>&#125;<br>    )<br>    <span class="hljs-built_in">print</span>(response.content)<br></code></pre></td></tr></table></figure>
<h3 id="server">3. Server</h3>
<h4 id="服务端">1. 服务端</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> fastapi <span class="hljs-keyword">import</span> FastAPI<br><span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate<br><span class="hljs-keyword">from</span> langchain_core.output_parsers <span class="hljs-keyword">import</span> StrOutputParser<br><span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI<br><span class="hljs-keyword">from</span> langserve <span class="hljs-keyword">import</span> add_routes<br><br><span class="hljs-comment"># 1. Create prompt template</span><br>system_template = <span class="hljs-string">&quot;Translate the following into &#123;language&#125;:&quot;</span><br>prompt_template = ChatPromptTemplate.from_messages([<br>    (<span class="hljs-string">&#x27;system&#x27;</span>, system_template),<br>    (<span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;&#123;text&#125;&#x27;</span>)<br>])<br><br><span class="hljs-comment"># 2. Create model</span><br>model = ChatOpenAI()<br><br><span class="hljs-comment"># 3. Create parser</span><br>parser = StrOutputParser()<br><br><span class="hljs-comment"># 4. Create chain</span><br>chain = prompt_template | model | parser<br><br><span class="hljs-comment"># 4. App definition</span><br>app = FastAPI(<br>    title=<span class="hljs-string">&quot;LangChain Server&quot;</span>,<br>    version=<span class="hljs-string">&quot;1.0&quot;</span>,<br>    description=<span class="hljs-string">&quot;A simple API server using LangChain&#x27;s Runnable interfaces&quot;</span>,<br>)<br><br><span class="hljs-comment"># 5. Adding chain route</span><br>add_routes(<br>    app,<br>    chain,<br>    path=<span class="hljs-string">&quot;/chain&quot;</span>,<br>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">import</span> uvicorn<br>    uvicorn.run(app, host=<span class="hljs-string">&quot;localhost&quot;</span>, port=<span class="hljs-number">8000</span>)<br></code></pre></td></tr></table></figure>
<h4 id="客户端">2. 客户端</h4>
<ol type="1">
<li><p><strong>服务调用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langserve <span class="hljs-keyword">import</span> RemoteRunnable<br><br>remote_chain = RemoteRunnable(<span class="hljs-string">&quot;http://localhost:8000/chain/&quot;</span>)<br>result = remote_chain.invoke(&#123;<span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: <span class="hljs-string">&quot;debug&quot;</span>&#125;)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure></li>
<li><p><strong>Playground</strong></p></li>
</ol>
<p><img src="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142032208.png" srcset="/img/loading.gif" lazyload style="zoom:25%;" /></p>
<h3 id="message-history">4. Message History</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> langchain_core.chat_history <span class="hljs-keyword">import</span> (<br>    BaseChatMessageHistory,<br>    InMemoryChatMessageHistory,<br>)<br><span class="hljs-keyword">from</span> langchain_core.runnables.history <span class="hljs-keyword">import</span> RunnableWithMessageHistory<br><br>store = &#123;&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_session_history</span>(<span class="hljs-params">session_id: <span class="hljs-built_in">str</span></span>) -&gt; BaseChatMessageHistory:</span><br>    <span class="hljs-keyword">if</span> session_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> store:<br>        store[session_id] = InMemoryChatMessageHistory()<br>    <span class="hljs-keyword">return</span> store[session_id]<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    with_message_history = RunnableWithMessageHistory(model, get_session_history)<br><br>    config = &#123;<span class="hljs-string">&quot;configurable&quot;</span>: &#123;<span class="hljs-string">&quot;session_id&quot;</span>: <span class="hljs-string">&quot;abc2&quot;</span>&#125;&#125;<br>    response = with_message_history.invoke(<br>        [HumanMessage(content=<span class="hljs-string">&quot;Hi! I&#x27;m Bob&quot;</span>)],<br>        config=config,<br>    )<br>    <span class="hljs-built_in">print</span>(response.content)<br><br>    response = with_message_history.invoke(<br>        [HumanMessage(content=<span class="hljs-string">&quot;What&#x27;s my name?&quot;</span>)],<br>        config=config,<br>    )<br>    <span class="hljs-built_in">print</span>(response.content)<br></code></pre></td></tr></table></figure>
<p><strong>结合 MessagesPlaceholder:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    prompt = ChatPromptTemplate.from_messages([<br>        (<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;You are a helpful assistant. Answer all questions to the best of your ability in &#123;language&#125;.&quot;</span>),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;messages&quot;</span>),<br>    ])<br><br>    chain = prompt | model<br>    with_message_history = RunnableWithMessageHistory(<br>        chain, get_session_history, input_messages_key=<span class="hljs-string">&quot;messages&quot;</span>,<br>    )<br>    config = &#123;<span class="hljs-string">&quot;configurable&quot;</span>: &#123;<span class="hljs-string">&quot;session_id&quot;</span>: <span class="hljs-string">&quot;abc11&quot;</span>&#125;&#125;<br>    response = with_message_history.invoke(<br>        &#123;<span class="hljs-string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="hljs-string">&quot;hi! I&#x27;m bob&quot;</span>)], <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span>&#125;,<br>        config=config,<br>    )<br>    <span class="hljs-built_in">print</span>(response.content)<br>    response = with_message_history.invoke(<br>        &#123;<span class="hljs-string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="hljs-string">&quot;whats my name?&quot;</span>)], <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span>&#125;,<br>        config=config,<br>    )<br>    <span class="hljs-built_in">print</span>(response.content)<br></code></pre></td></tr></table></figure>
<h3 id="managing-conversation-history">5. Managing Conversation
History</h3>
<p>　　LangChain comes with a few built-in helpers for <a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/#messages">managing
a list of messages</a>. In this case we'll use the <a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/">trim_messages</a>
helper to reduce how many messages we're sending to the model. The
trimmer allows us to specify how many tokens we want to keep, along with
other parameters like if we want to always keep the system message and
whether to allow partial messages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    messages = [<br>        SystemMessage(content=<span class="hljs-string">&quot;you&#x27;re a good assistant&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;hi! I&#x27;m bob&quot;</span>),<br>        AIMessage(content=<span class="hljs-string">&quot;hi!&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;I like vanilla ice cream&quot;</span>),<br>        AIMessage(content=<span class="hljs-string">&quot;nice&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;whats 2 + 2&quot;</span>),<br>        AIMessage(content=<span class="hljs-string">&quot;4&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;thanks&quot;</span>),<br>        AIMessage(content=<span class="hljs-string">&quot;no problem!&quot;</span>),<br>        HumanMessage(content=<span class="hljs-string">&quot;having fun?&quot;</span>),<br>        AIMessage(content=<span class="hljs-string">&quot;yes!&quot;</span>),<br>    ]<br><br>    trimmer = trim_messages(<br>        max_tokens=<span class="hljs-number">65</span>, strategy=<span class="hljs-string">&quot;last&quot;</span>, token_counter=model, include_system=<span class="hljs-literal">True</span>, allow_partial=<span class="hljs-literal">False</span>, start_on=<span class="hljs-string">&quot;human&quot;</span>,<br>    )<br>    <span class="hljs-comment">#result = trimmer.invoke(messages)</span><br>    <span class="hljs-comment">#print(result)</span><br><br>    prompt = ChatPromptTemplate.from_messages([<br>        (<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;You are a helpful assistant. Answer all questions to the best of your ability in &#123;language&#125;.&quot;</span>),<br>        MessagesPlaceholder(variable_name=<span class="hljs-string">&quot;messages&quot;</span>),<br>    ])<br><br>    chain = (RunnablePassthrough.assign(messages=itemgetter(<span class="hljs-string">&quot;messages&quot;</span>) | trimmer) | prompt | model)<br><br>    response = chain.invoke(&#123;<br>        <span class="hljs-string">&quot;messages&quot;</span>: messages + [HumanMessage(content=<span class="hljs-string">&quot;what&#x27;s my name?&quot;</span>)],<br>        <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;English&quot;</span>,<br>    &#125;)<br>    <span class="hljs-built_in">print</span>(response.content)<br></code></pre></td></tr></table></figure>
<p><strong>结合 Message History：</strong></p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ChatOpenAI(<span class="hljs-attribute">model</span>=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>)<br><br>    trimmer = trim_messages(<br>        <span class="hljs-attribute">max_tokens</span>=200, <span class="hljs-attribute">strategy</span>=<span class="hljs-string">&quot;last&quot;</span>, <span class="hljs-attribute">token_counter</span>=model, <span class="hljs-attribute">include_system</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">allow_partial</span>=<span class="hljs-literal">False</span>,<br>        <span class="hljs-attribute">start_on</span>=<span class="hljs-string">&quot;human&quot;</span>,<br>    )<br><br>    prompt = ChatPromptTemplate.from_messages([<br>        (<span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;You are a helpful assistant. Answer all questions to the best of your ability in &#123;language&#125;.&quot;</span>),<br>        MessagesPlaceholder(<span class="hljs-attribute">variable_name</span>=<span class="hljs-string">&quot;messages&quot;</span>),<br>    ])<br><br>    chain = (RunnablePassthrough.assign(<span class="hljs-attribute">messages</span>=itemgetter(&quot;messages&quot;) | trimmer) | prompt | model)<br>    with_message_history = RunnableWithMessageHistory(<br>        chain, get_session_history, <span class="hljs-attribute">input_messages_key</span>=<span class="hljs-string">&quot;messages&quot;</span>,<br>    )<br><br>   <span class="hljs-built_in"> config </span>= &#123;<span class="hljs-string">&quot;configurable&quot;</span>: &#123;<span class="hljs-string">&quot;session_id&quot;</span>: <span class="hljs-string">&quot;debuggingWorld&quot;</span>&#125;&#125;<br><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        question = input(<span class="hljs-string">&quot;请输入: &quot;</span>)<br>        response = with_message_history.invoke(<br>            &#123;<br>                <span class="hljs-string">&quot;messages&quot;</span>: [HumanMessage(<span class="hljs-attribute">content</span>=question)],<br>                <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;English&quot;</span>,<br>            &#125;,<br>            <span class="hljs-attribute">config</span>=config,<br>        )<br>        <span class="hljs-builtin-name">print</span>(response.content)<br>        msgs = trimmer.invoke(get_session_history(<span class="hljs-string">&quot;debuggingWorld&quot;</span>).messages)<br>        <span class="hljs-builtin-name">print</span>(msgs)<br></code></pre></td></tr></table></figure>
<h3 id="streaming">6. Streaming</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> resp <span class="hljs-keyword">in</span> with_message_history.stream(<br>        &#123;<br>            <span class="hljs-string">&quot;messages&quot;</span>: [HumanMessage(content=question)],<br>            <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;English&quot;</span>,<br>        &#125;,<br>        config=config,<br>):<br>    <span class="hljs-built_in">print</span>(resp.content)<br></code></pre></td></tr></table></figure>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">#人工智能</a>
      
        <a href="/tags/LangChain/">#LangChain</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>LangChain——开篇</div>
      <div>http://example.com/2024/08/14/LangChain——开篇/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>debuggingWorld</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年8月14日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/08/16/NLP%E2%80%94%E2%80%94GPT/" title="NLP——GPT&amp;BERT">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">NLP——GPT&amp;BERT</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/08/11/NLP%E2%80%94%E2%80%94Transformer%E6%A8%A1%E5%9E%8B/" title="NLP——Transformer模型">
                        <span class="hidden-mobile">NLP——Transformer模型</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'debuggingworld/blogUtterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <img src="https://debugging.oss-cn-hangzhou.aliyuncs.com/太空探索与卫星.svg" srcset="/img/loading.gif" lazyload height="250" width="250" /> <br/> <a>没有什么能够阻挡，你对自由的向往</a> <br/> <a>天马行空的生涯，你的心了无牵挂</a> <br/> <br/> <br/> <br> <font size="2" >--end--</font> <br/> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>






  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.0/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="/iconfont.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
