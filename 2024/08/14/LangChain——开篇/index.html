

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="https://debugging.oss-cn-hangzhou.aliyuncs.com/debugIcon.jpg">
  <link rel="icon" href="https://debugging.oss-cn-hangzhou.aliyuncs.com/debugIcon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="debuggingWorld">
  <meta name="keywords" content="">
  
    <meta name="description" content="1. 整体架构 　　LangChain是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。  langchain-core: 基础抽象和 LangChain 表达式语言。 langchain-community：第三方集成。  例如 langchain-openai、langchain-anthropic 等。  langchain: Chains, agents, and retriev">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain——开篇">
<meta property="og:url" content="http://example.com/2024/08/14/LangChain%E2%80%94%E2%80%94%E5%BC%80%E7%AF%87/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. 整体架构 　　LangChain是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。  langchain-core: 基础抽象和 LangChain 表达式语言。 langchain-community：第三方集成。  例如 langchain-openai、langchain-anthropic 等。  langchain: Chains, agents, and retriev">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142032208.png">
<meta property="article:published_time" content="2024-08-14T03:10:02.000Z">
<meta property="article:modified_time" content="2025-09-01T02:21:27.784Z">
<meta property="article:author" content="debuggingWorld">
<meta property="article:tag" content="人工智能">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142032208.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>LangChain——开篇 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/iconfont.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.0","typing":{"enable":true,"typeSpeed":90,"cursorChar":"<img src=\"https://debugging.oss-cn-hangzhou.aliyuncs.com/喜爱.png\" height=\"35\" width=\"35\" />","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>

  
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>猫和少年</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('https://debugging.oss-cn-hangzhou.aliyuncs.com/art_bg.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="LangChain——开篇"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-08-14 11:10" pubdate>
          2024年8月14日 上午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          8.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          <!-- compatible with older versions-->
          26 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">LangChain——开篇</h1>
            
            <div class="markdown-body">
              
              <h3 id="整体架构">1. 整体架构</h3>
<p>　　<strong>LangChain</strong>是一个用于开发由大型语言模型（LLM）驱动的应用程序的框架。</p>
<ul>
<li><strong><code>langchain-core</code></strong>: 基础抽象和 LangChain
表达式语言。</li>
<li><strong><code>langchain-community</code></strong>：第三方集成。
<ul>
<li>例如 langchain-openai、langchain-anthropic 等。</li>
</ul></li>
<li><strong><code>langchain</code></strong>: Chains, agents, and
retrieval strategies that make up an application's cognitive
architecture.</li>
<li><strong><code>LangGraph</code></strong>: Build robust and stateful
multi-actor applications with LLMs by modeling steps as edges and nodes
in a graph.</li>
<li><strong><code>LangServe</code></strong>: Deploy LangChain chains as
REST APIs.</li>
<li><strong><code>LangSmith</code></strong>: A developer platform that
lets you debug, test, evaluate, and monitor LLM applications.</li>
</ul>
<p><img
src="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142057648.svg" srcset="/img/loading.gif" lazyload /></p>
<p><a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/introduction/">【传送门】</a></p>
<h3 id="使用llm">2. 使用LLM</h3>
<p><a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/tutorials/llm_chain/">【传送门】</a></p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    messages <span class="token operator">=</span> <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Translate the following from English into chinese"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    llmResult <span class="token operator">=</span> model<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
    parser <span class="token operator">=</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> parser<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>llmResult<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<p>链式调用：</p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> HumanMessage<span class="token punctuation">,</span> SystemMessage
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAI<span class="token punctuation">,</span> ChatOpenAI


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    messages <span class="token operator">=</span> <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Translate the following from English into chinese"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    parser <span class="token operator">=</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
    chain <span class="token operator">=</span> model <span class="token operator">|</span> parser
    result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<h3 id="prompttemplates">2. PromptTemplates</h3>
<p>　　PromptTemplates are a concept in LangChain designed to assist
with this transformation. They take in raw user input and return data (a
prompt) that is ready to pass into a language model.</p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python">system_template <span class="token operator">=</span> <span class="token string">"Translate the following into &#123;language&#125;:"</span>
prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> system_template<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"&#123;text&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>
<span class="token comment"># 查看转换结果</span>
messages <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"chinese"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> <span class="token string">"hi"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>messages<span class="token punctuation">.</span>to_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<p><strong>Chaining together components with LCEL(LangChain Expression
Language )</strong></p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>
    parser <span class="token operator">=</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

    system_template <span class="token operator">=</span> <span class="token string">"Translate the following into &#123;language&#125;:"</span>
    prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>
        <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> system_template<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"&#123;text&#125;"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>

    chain <span class="token operator">=</span> prompt_template <span class="token operator">|</span> model <span class="token operator">|</span> parser
    result <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"chinese"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> <span class="token string">"hi"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<p><strong>MessagesPlaceholder 方式：</strong></p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>
        <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant. Answer all questions to the best of your ability."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         MessagesPlaceholder<span class="token punctuation">(</span>variable_name<span class="token operator">=</span><span class="token string">"messages"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>

    chain <span class="token operator">=</span> prompt <span class="token operator">|</span> model
    response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"messages"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi! I'm bob"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<p><strong>两种方式结合：</strong></p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>
        <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"Answer all questions to the best of your ability in &#123;language&#125;."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         MessagesPlaceholder<span class="token punctuation">(</span>variable_name<span class="token operator">=</span><span class="token string">"messages"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>

    chain <span class="token operator">=</span> prompt <span class="token operator">|</span> model
    response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
        <span class="token punctuation">&#123;</span><span class="token string">"messages"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"debug the world"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"chinese"</span><span class="token punctuation">&#125;</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<h3 id="server">3. Server</h3>
<h4 id="服务端">1. 服务端</h4>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> fastapi <span class="token keyword">import</span> FastAPI
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langserve <span class="token keyword">import</span> add_routes

<span class="token comment"># 1. Create prompt template</span>
system_template <span class="token operator">=</span> <span class="token string">"Translate the following into &#123;language&#125;:"</span>
prompt_template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">'system'</span><span class="token punctuation">,</span> system_template<span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'&#123;text&#125;'</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 2. Create model</span>
model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 3. Create parser</span>
parser <span class="token operator">=</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 4. Create chain</span>
chain <span class="token operator">=</span> prompt_template <span class="token operator">|</span> model <span class="token operator">|</span> parser

<span class="token comment"># 4. App definition</span>
app <span class="token operator">=</span> FastAPI<span class="token punctuation">(</span>
    title<span class="token operator">=</span><span class="token string">"LangChain Server"</span><span class="token punctuation">,</span>
    version<span class="token operator">=</span><span class="token string">"1.0"</span><span class="token punctuation">,</span>
    description<span class="token operator">=</span><span class="token string">"A simple API server using LangChain's Runnable interfaces"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># 5. Adding chain route</span>
add_routes<span class="token punctuation">(</span>
    app<span class="token punctuation">,</span>
    chain<span class="token punctuation">,</span>
    path<span class="token operator">=</span><span class="token string">"/chain"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    <span class="token keyword">import</span> uvicorn
    uvicorn<span class="token punctuation">.</span>run<span class="token punctuation">(</span>app<span class="token punctuation">,</span> host<span class="token operator">=</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<h4 id="客户端">2. 客户端</h4>
<ol type="1">
<li><p><strong>服务调用</strong></p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langserve <span class="token keyword">import</span> RemoteRunnable

remote_chain <span class="token operator">=</span> RemoteRunnable<span class="token punctuation">(</span><span class="token string">"http://localhost:8000/chain/"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> remote_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">&#123;</span><span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"chinese"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> <span class="token string">"debug"</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></div></li>
<li><p><strong>Playground</strong></p></li>
</ol>
<p><img src="https://debugging.oss-cn-hangzhou.aliyuncs.com/202408142032208.png" srcset="/img/loading.gif" lazyload style="zoom:25%;" /></p>
<h3 id="message-history">4. Message History</h3>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>chat_history <span class="token keyword">import</span> <span class="token punctuation">(</span>
    BaseChatMessageHistory<span class="token punctuation">,</span>
    InMemoryChatMessageHistory<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables<span class="token punctuation">.</span>history <span class="token keyword">import</span> RunnableWithMessageHistory

store <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>

<span class="token keyword">def</span> <span class="token function">get_session_history</span><span class="token punctuation">(</span>session_id<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> BaseChatMessageHistory<span class="token punctuation">:</span>
    <span class="token keyword">if</span> session_id <span class="token keyword">not</span> <span class="token keyword">in</span> store<span class="token punctuation">:</span>
        store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span> <span class="token operator">=</span> InMemoryChatMessageHistory<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    with_message_history <span class="token operator">=</span> RunnableWithMessageHistory<span class="token punctuation">(</span>model<span class="token punctuation">,</span> get_session_history<span class="token punctuation">)</span>

    config <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"configurable"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"session_id"</span><span class="token punctuation">:</span> <span class="token string">"abc2"</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span>
    response <span class="token operator">=</span> with_message_history<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Hi! I'm Bob"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span>config<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>

    response <span class="token operator">=</span> with_message_history<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"What's my name?"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span>config<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<p><strong>结合 MessagesPlaceholder:</strong></p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant. Answer all questions to the best of your ability in &#123;language&#125;."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        MessagesPlaceholder<span class="token punctuation">(</span>variable_name<span class="token operator">=</span><span class="token string">"messages"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>

    chain <span class="token operator">=</span> prompt <span class="token operator">|</span> model
    with_message_history <span class="token operator">=</span> RunnableWithMessageHistory<span class="token punctuation">(</span>
        chain<span class="token punctuation">,</span> get_session_history<span class="token punctuation">,</span> input_messages_key<span class="token operator">=</span><span class="token string">"messages"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    config <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"configurable"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token string">"session_id"</span><span class="token punctuation">:</span> <span class="token string">"abc11"</span><span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span>
    response <span class="token operator">=</span> with_message_history<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
        <span class="token punctuation">&#123;</span><span class="token string">"messages"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi! I'm bob"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"chinese"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span>config<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
    response <span class="token operator">=</span> with_message_history<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>
        <span class="token punctuation">&#123;</span><span class="token string">"messages"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"whats my name?"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"chinese"</span><span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span>config<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<h3 id="managing-conversation-history">5. Managing Conversation
History</h3>
<p>　　LangChain comes with a few built-in helpers for <a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/#messages">managing
a list of messages</a>. In this case we'll use the <a
target="_blank" rel="noopener" href="https://python.langchain.com/v0.2/docs/how_to/trim_messages/">trim_messages</a>
helper to reduce how many messages we're sending to the model. The
trimmer allows us to specify how many tokens we want to keep, along with
other parameters like if we want to always keep the system message and
whether to allow partial messages:</p>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">)</span>

    messages <span class="token operator">=</span> <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"you're a good assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi! I'm bob"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"hi!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"I like vanilla ice cream"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"nice"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"whats 2 + 2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"thanks"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"no problem!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"having fun?"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"yes!"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    trimmer <span class="token operator">=</span> trim_messages<span class="token punctuation">(</span>
        max_tokens<span class="token operator">=</span><span class="token number">65</span><span class="token punctuation">,</span> strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span> token_counter<span class="token operator">=</span>model<span class="token punctuation">,</span> include_system<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allow_partial<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> start_on<span class="token operator">=</span><span class="token string">"human"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token comment">#result = trimmer.invoke(messages)</span>
    <span class="token comment">#print(result)</span>

    prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful assistant. Answer all questions to the best of your ability in &#123;language&#125;."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        MessagesPlaceholder<span class="token punctuation">(</span>variable_name<span class="token operator">=</span><span class="token string">"messages"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>

    chain <span class="token operator">=</span> <span class="token punctuation">(</span>RunnablePassthrough<span class="token punctuation">.</span>assign<span class="token punctuation">(</span>messages<span class="token operator">=</span>itemgetter<span class="token punctuation">(</span><span class="token string">"messages"</span><span class="token punctuation">)</span> <span class="token operator">|</span> trimmer<span class="token punctuation">)</span> <span class="token operator">|</span> prompt <span class="token operator">|</span> model<span class="token punctuation">)</span>

    response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        <span class="token string">"messages"</span><span class="token punctuation">:</span> messages <span class="token operator">+</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"what's my name?"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"English"</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<p><strong>结合 Message History：</strong></p>
<div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:
    model &#x3D; ChatOpenAI(model&#x3D;&quot;gpt-3.5-turbo&quot;)

    trimmer &#x3D; trim_messages(
        max_tokens&#x3D;200, strategy&#x3D;&quot;last&quot;, token_counter&#x3D;model, include_system&#x3D;True, allow_partial&#x3D;False,
        start_on&#x3D;&quot;human&quot;,
    )

    prompt &#x3D; ChatPromptTemplate.from_messages([
        (&quot;system&quot;, &quot;You are a helpful assistant. Answer all questions to the best of your ability in &#123;language&#125;.&quot;),
        MessagesPlaceholder(variable_name&#x3D;&quot;messages&quot;),
    ])

    chain &#x3D; (RunnablePassthrough.assign(messages&#x3D;itemgetter(&quot;messages&quot;) | trimmer) | prompt | model)
    with_message_history &#x3D; RunnableWithMessageHistory(
        chain, get_session_history, input_messages_key&#x3D;&quot;messages&quot;,
    )

    config &#x3D; &#123;&quot;configurable&quot;: &#123;&quot;session_id&quot;: &quot;debuggingWorld&quot;&#125;&#125;

    while True:
        question &#x3D; input(&quot;请输入: &quot;)
        response &#x3D; with_message_history.invoke(
            &#123;
                &quot;messages&quot;: [HumanMessage(content&#x3D;question)],
                &quot;language&quot;: &quot;English&quot;,
            &#125;,
            config&#x3D;config,
        )
        print(response.content)
        msgs &#x3D; trimmer.invoke(get_session_history(&quot;debuggingWorld&quot;).messages)
        print(msgs)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>
<h3 id="streaming">6. Streaming</h3>
<div class="code-wrapper"><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> resp <span class="token keyword">in</span> with_message_history<span class="token punctuation">.</span>stream<span class="token punctuation">(</span>
        <span class="token punctuation">&#123;</span>
            <span class="token string">"messages"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span>question<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">"language"</span><span class="token punctuation">:</span> <span class="token string">"English"</span><span class="token punctuation">,</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        config<span class="token operator">=</span>config<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>resp<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></div>

              
            </div>
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="category-chain-item">人工智能</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">#人工智能</a>
      
        <a href="/tags/LangChain/">#LangChain</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>LangChain——开篇</div>
      <div>http://example.com/2024/08/14/LangChain——开篇/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>debuggingWorld</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年8月14日</div>
        </div>
      
      
      <div class="license-meta-item">
        <div>许可协议</div>
        <div>
          
            
            
              <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
              <span class="hint--top hint--rounded" aria-label="BY - 署名">
                <i class="iconfont icon-by"></i>
              </span>
              </a>
            
          
        </div>
      </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/08/16/NLP%E2%80%94%E2%80%94GPT/" title="NLP——GPT&amp;BERT">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">NLP——GPT&amp;BERT</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/08/11/NLP%E2%80%94%E2%80%94Transformer%E6%A8%A1%E5%9E%8B/" title="NLP——Transformer模型">
                        <span class="hidden-mobile">NLP——Transformer模型</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'debuggingworld/blogUtterances');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  








    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <img src="https://debugging.oss-cn-hangzhou.aliyuncs.com/太空探索与卫星.svg" srcset="/img/loading.gif" lazyload height="250" width="250" /> <br/> <a>没有什么能够阻挡，你对自由的向往</a> <br/> <a>天马行空的生涯，你的心了无牵挂</a> <br/> <br/> <br/> <br> <font size="2" >--end--</font> <br/> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>






  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script  src="https://lib.baomitu.com/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.js" ></script>

  <script>
  (function() {
    var enableLang = CONFIG.code_language.enable && CONFIG.code_language.default;
    var enableCopy = CONFIG.copy_btn;
    if (!enableLang && !enableCopy) {
      return;
    }

    function getBgClass(ele) {
      return Fluid.utils.getBackgroundLightness(ele) >= 0 ? 'code-widget-light' : 'code-widget-dark';
    }

    var copyTmpl = '';
    copyTmpl += '<div class="code-widget">';
    copyTmpl += 'LANG';
    copyTmpl += '</div>';
    jQuery('.markdown-body pre').each(function() {
      var $pre = jQuery(this);
      if ($pre.find('code.mermaid').length > 0) {
        return;
      }
      if ($pre.find('span.line').length > 0) {
        return;
      }

      var lang = '';

      if (enableLang) {
        lang = CONFIG.code_language.default;
        if ($pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2 && $pre.children().hasClass('hljs')) {
          lang = $pre[0].children[0].classList[1];
        } else if ($pre[0].getAttribute('data-language')) {
          lang = $pre[0].getAttribute('data-language');
        } else if ($pre.parent().hasClass('sourceCode') && $pre[0].children.length > 0 && $pre[0].children[0].classList.length >= 2) {
          lang = $pre[0].children[0].classList[1];
          $pre.parent().addClass('code-wrapper');
        } else if ($pre.parent().hasClass('markdown-body') && $pre[0].classList.length === 0) {
          $pre.wrap('<div class="code-wrapper"></div>');
        }
        lang = lang.toUpperCase().replace('NONE', CONFIG.code_language.default);
      }
      $pre.append(copyTmpl.replace('LANG', lang).replace('code-widget">',
        getBgClass($pre[0]) + (enableCopy ? ' code-widget copy-btn" data-clipboard-snippet><i class="iconfont icon-copy"></i>' : ' code-widget">')));

      if (enableCopy) {
        Fluid.utils.createScript('https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js', function() {
          var clipboard = new window.ClipboardJS('.copy-btn', {
            target: function(trigger) {
              var nodes = trigger.parentNode.childNodes;
              for (var i = 0; i < nodes.length; i++) {
                if (nodes[i].tagName === 'CODE') {
                  return nodes[i];
                }
              }
            }
          });
          clipboard.on('success', function(e) {
            e.clearSelection();
            e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-copy', 'icon-success');
            setTimeout(function() {
              e.trigger.innerHTML = e.trigger.innerHTML.replace('icon-success', 'icon-copy');
            }, 2000);
          });
        });
      }
    });
  })();
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        MathJax = {
          tex    : {
            inlineMath: { '[+]': [['$', '$']] }
          },
          loader : {
            load: ['ui/lazy']
          },
          options: {
            renderActions: {
              findScript    : [10, doc => {
                document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                  const display = !!node.type.match(/; *mode=display/);
                  const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                  const text = document.createTextNode('');
                  node.parentNode.replaceChild(text, node);
                  math.start = { node: text, delim: '', n: 0 };
                  math.end = { node: text, delim: '', n: 0 };
                  doc.math.push(math);
                });
              }, '', false],
              insertedScript: [200, () => {
                document.querySelectorAll('mjx-container').forEach(node => {
                  let target = node.parentNode;
                  if (target.nodeName.toLowerCase() === 'li') {
                    target.parentNode.classList.add('has-jax');
                  }
                });
              }, '', false]
            }
          }
        };
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.0/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  
<script src="/iconfont.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
